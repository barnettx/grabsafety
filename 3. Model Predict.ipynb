{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libaries to Install\n",
    "- Built in Anaconda Environment\n",
    "- Installed Keras and Tensorflow on top\n",
    "- Using Tensorflow as the backend. (Set this by using the file explorer to navigate to \"%USERPROFILE%/.keras/keras.json\" and changing \"backend\" to \"tensorflow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "from keras.models import load_model\n",
    "\n",
    "import seaborn as sns\n",
    "from sklearn.externals import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Files for Prediction\n",
    "Kindly put test data into the \"TEST DATA HERE\" folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace with the locaiton of the features\n",
    "filename = \"./TEST DATA HERE/features/\"+\"part-00000-e6120af0-10c2-4248-97c4-81baf4304e5c-c000.csv\"\n",
    "data_features = pd.read_csv(filename,header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace with the locaiton of the features\n",
    "filename = \"./TEST DATA HERE/labels/\"+\"part-00000-e9445087-aa0a-433b-a7f6-7f4c19d78ad6-c000.csv\"\n",
    "data_labels = pd.read_csv(filename,header=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_features(df):\n",
    "    #rename to more uniform convention\n",
    "    df.columns = ['bookingID', 'accuracy', 'bearing', \n",
    "                    'acceleration_x', 'acceleration_y', 'acceleration_z',\n",
    "                    'gyro_x', 'gyro_y', 'gyro_z',\n",
    "                    'second','speed']\n",
    "    #remove NAs\n",
    "    df = df.dropna()\n",
    "    df = df.drop_duplicates()\n",
    "    df = df.loc[(df[\"accuracy\"]<20) &\n",
    "                (df[\"second\"]<1e6) &\n",
    "                (df[\"speed\"]>0) &\n",
    "                (df[\"speed\"]<60)]\n",
    "    return df\n",
    "\n",
    "def clean_labels(df):\n",
    "    df = df.dropna()\n",
    "    df = df.drop_duplicates(\"bookingID\", keep=\"last\") #some booking IDs have multiple labels. set them to be dangerous\n",
    "    return df\n",
    "\n",
    "def process_data(features, labels):\n",
    "    temp_features = clean_features(features)\n",
    "    temp_labels = clean_labels(labels)\n",
    "    data_combined = data = pd.merge(temp_features, temp_labels, how=\"inner\",on=\"bookingID\")\n",
    "    return data_combined\n",
    "\n",
    "data_combined = process_data(data_features, data_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = joblib.load(\"standard_scaler.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_model = load_model(\"train_model_all_data.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_combined[[\"bookingID\",\n",
    "      \"accuracy\",\n",
    "      \"bearing\",\n",
    "      \"acceleration_x\",\"acceleration_y\",\"acceleration_z\",\n",
    "      \"gyro_x\",\"gyro_y\",\"gyro_z\",\n",
    "      \"second\",\n",
    "      \"speed\"]]\n",
    "y = data_combined[[\"label\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Barnett\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "X_standardised = scaler.transform(X)\n",
    "y_pred = keras_model.predict_classes(X_standardised)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1278397/1278397 [==============================] - 17s 13us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5828630390650341, 0.7218876452302406, 0.19385076910205712]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras_model.evaluate(X_standardised, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[876210  21162]\n",
      " [334376  46649]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.98      0.83    897372\n",
      "           1       0.69      0.12      0.21    381025\n",
      "\n",
      "   micro avg       0.72      0.72      0.72   1278397\n",
      "   macro avg       0.71      0.55      0.52   1278397\n",
      "weighted avg       0.71      0.72      0.65   1278397\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
