{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "\n",
    "import seaborn as sns\n",
    "from sklearn.externals import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Barnett\\Anaconda3\\lib\\site-packages\\numpy\\lib\\arraysetops.py:569: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    }
   ],
   "source": [
    "data_combined = pd.read_csv('./data_combined.csv', header=0, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_combined.sort_values([\"bookingID\",\"second\"], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_combined[[\"bookingID\",\n",
    "      \"accuracy\",\n",
    "      \"bearing\",\n",
    "      \"acceleration_x\",\"acceleration_y\",\"acceleration_z\",\n",
    "      \"gyro_x\",\"gyro_y\",\"gyro_z\",\n",
    "      \"second\",\n",
    "      \"speed\"]]\n",
    "y = data_combined[[\"label\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standardise data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Barnett\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\Barnett\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  \n",
      "C:\\Users\\Barnett\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train_standardised = scaler.transform(X_train)\n",
    "X_test_standardised = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save our scaler for predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['standard_scaler.pkl']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(scaler, 'standard_scaler.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Models\n",
    "Referencing: https://scikit-learn.org/stable/tutorial/machine_learning_map/index.html\n",
    "Testing with Stochastic Descent Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Barnett\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Barnett\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 501698743.20, NNZs: 11, Bias: -918.112464, T: 9587388, Avg. loss: 1858667540244959854592.000000\n",
      "Total training time: 2.66 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 510684044.78, NNZs: 11, Bias: -1004.084896, T: 19174776, Avg. loss: 142349671274378428416.000000\n",
      "Total training time: 5.77 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 223995207.46, NNZs: 11, Bias: -1054.878276, T: 28762164, Avg. loss: 83292911599083274240.000000\n",
      "Total training time: 8.75 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 248611019.02, NNZs: 11, Bias: -1090.870683, T: 38349552, Avg. loss: 59077932193983889408.000000\n",
      "Total training time: 11.50 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 16143723.11, NNZs: 11, Bias: -1118.751154, T: 47936940, Avg. loss: 45871917149434617856.000000\n",
      "Total training time: 14.29 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 243386800.89, NNZs: 11, Bias: -1141.335130, T: 57524328, Avg. loss: 37467509710910046208.000000\n",
      "Total training time: 17.22 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 70384737.15, NNZs: 11, Bias: -1160.519644, T: 67111716, Avg. loss: 31660047996946972672.000000\n",
      "Total training time: 20.21 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 36972139.56, NNZs: 11, Bias: -1177.327150, T: 76699104, Avg. loss: 27416352793935941632.000000\n",
      "Total training time: 23.31 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 59719076.96, NNZs: 11, Bias: -1192.051841, T: 86286492, Avg. loss: 24177323474245242880.000000\n",
      "Total training time: 26.11 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 28685243.87, NNZs: 11, Bias: -1205.417032, T: 95873880, Avg. loss: 21639522636746711040.000000\n",
      "Total training time: 29.27 seconds.\n"
     ]
    }
   ],
   "source": [
    "sgd = SGDClassifier(verbose=100, alpha=1e-4, loss='hinge', max_iter=10)\n",
    "history = sgd.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd.score(X_test_standardised, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = sgd.predict(X_test_standardised)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Barnett\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Barnett\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      1.00      0.82   2243447\n",
      "           1       0.00      0.00      0.00    952350\n",
      "\n",
      "   micro avg       0.70      0.70      0.70   3195797\n",
      "   macro avg       0.35      0.50      0.41   3195797\n",
      "weighted avg       0.49      0.70      0.58   3195797\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Barnett\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2243447       0]\n",
      " [ 952350       0]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sgd_1000_all_data.pkl']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(sgd, 'sgd_1000_all_data.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning Model (Chosen Model for Final Prediction)\n",
    "\n",
    "SKlearn not really working out, trying KERAS instead. Built this on Google Colab: https://colab.research.google.com/drive/1Z6KMx3Se87_JhAv5AqL_NYmkjhWkn88a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 3410
    },
    "colab_type": "code",
    "id": "f0IqCMTslG7h",
    "outputId": "39d8fe43-9cd6-48b1-eb24-81641fd11a68"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9587388 samples, validate on 3195797 samples\n",
      "Epoch 1/100\n",
      " - 430s - loss: 0.5766 - acc: 0.7194 - mean_squared_error: 0.1949 - val_loss: 0.5763 - val_acc: 0.7199 - val_mean_squared_error: 0.1946\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.71989, saving model to train_model_all_data.h5\n",
      "Epoch 2/100\n",
      " - 437s - loss: 0.5751 - acc: 0.7205 - mean_squared_error: 0.1943 - val_loss: 0.5739 - val_acc: 0.7207 - val_mean_squared_error: 0.1939\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.71989 to 0.72074, saving model to train_model_all_data.h5\n",
      "Epoch 3/100\n",
      " - 429s - loss: 0.5749 - acc: 0.7210 - mean_squared_error: 0.1940 - val_loss: 0.5751 - val_acc: 0.7212 - val_mean_squared_error: 0.1938\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.72074 to 0.72123, saving model to train_model_all_data.h5\n",
      "Epoch 4/100\n",
      " - 430s - loss: 0.5754 - acc: 0.7209 - mean_squared_error: 0.1940 - val_loss: 0.5745 - val_acc: 0.7210 - val_mean_squared_error: 0.1938\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.72123\n",
      "Epoch 5/100\n",
      " - 432s - loss: 0.5756 - acc: 0.7208 - mean_squared_error: 0.1939 - val_loss: 0.5740 - val_acc: 0.7209 - val_mean_squared_error: 0.1937\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.72123\n",
      "Epoch 6/100\n",
      " - 433s - loss: 0.5759 - acc: 0.7207 - mean_squared_error: 0.1939 - val_loss: 0.5737 - val_acc: 0.7196 - val_mean_squared_error: 0.1938\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.72123\n",
      "Epoch 7/100\n",
      " - 431s - loss: 0.5762 - acc: 0.7207 - mean_squared_error: 0.1940 - val_loss: 0.5770 - val_acc: 0.7213 - val_mean_squared_error: 0.1936\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.72123 to 0.72129, saving model to train_model_all_data.h5\n",
      "Epoch 8/100\n",
      " - 430s - loss: 0.5763 - acc: 0.7208 - mean_squared_error: 0.1939 - val_loss: 0.5838 - val_acc: 0.7208 - val_mean_squared_error: 0.1944\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.72129\n",
      "Epoch 9/100\n",
      " - 429s - loss: 0.5766 - acc: 0.7207 - mean_squared_error: 0.1940 - val_loss: 0.5803 - val_acc: 0.7204 - val_mean_squared_error: 0.1943\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.72129\n",
      "Epoch 10/100\n",
      " - 430s - loss: 0.5770 - acc: 0.7207 - mean_squared_error: 0.1940 - val_loss: 0.5752 - val_acc: 0.7209 - val_mean_squared_error: 0.1939\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.72129\n",
      "Epoch 11/100\n",
      " - 425s - loss: 0.5777 - acc: 0.7207 - mean_squared_error: 0.1941 - val_loss: 0.5789 - val_acc: 0.7213 - val_mean_squared_error: 0.1940\n",
      "\n",
      "Epoch 00011: val_acc improved from 0.72129 to 0.72133, saving model to train_model_all_data.h5\n",
      "Epoch 12/100\n",
      " - 425s - loss: 0.5783 - acc: 0.7206 - mean_squared_error: 0.1941 - val_loss: 0.5794 - val_acc: 0.7213 - val_mean_squared_error: 0.1941\n",
      "\n",
      "Epoch 00012: val_acc improved from 0.72133 to 0.72134, saving model to train_model_all_data.h5\n",
      "Epoch 13/100\n",
      " - 425s - loss: 0.5789 - acc: 0.7206 - mean_squared_error: 0.1942 - val_loss: 0.5768 - val_acc: 0.7211 - val_mean_squared_error: 0.1938\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.72134\n",
      "Epoch 14/100\n",
      " - 425s - loss: 0.5796 - acc: 0.7205 - mean_squared_error: 0.1942 - val_loss: 0.5838 - val_acc: 0.7214 - val_mean_squared_error: 0.1943\n",
      "\n",
      "Epoch 00014: val_acc improved from 0.72134 to 0.72140, saving model to train_model_all_data.h5\n",
      "Epoch 15/100\n",
      " - 428s - loss: 0.5803 - acc: 0.7205 - mean_squared_error: 0.1943 - val_loss: 0.5834 - val_acc: 0.7214 - val_mean_squared_error: 0.1941\n",
      "\n",
      "Epoch 00015: val_acc improved from 0.72140 to 0.72141, saving model to train_model_all_data.h5\n",
      "Epoch 16/100\n",
      " - 428s - loss: 0.5811 - acc: 0.7203 - mean_squared_error: 0.1944 - val_loss: 0.5818 - val_acc: 0.7211 - val_mean_squared_error: 0.1947\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.72141\n",
      "Epoch 17/100\n",
      " - 426s - loss: 0.5826 - acc: 0.7201 - mean_squared_error: 0.1945 - val_loss: 0.5780 - val_acc: 0.7209 - val_mean_squared_error: 0.1938\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.72141\n",
      "Epoch 18/100\n",
      " - 430s - loss: 0.5841 - acc: 0.7198 - mean_squared_error: 0.1946 - val_loss: 0.5780 - val_acc: 0.7202 - val_mean_squared_error: 0.1941\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.72141\n",
      "Epoch 19/100\n",
      " - 428s - loss: 0.5863 - acc: 0.7195 - mean_squared_error: 0.1948 - val_loss: 0.5834 - val_acc: 0.7193 - val_mean_squared_error: 0.1945\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.72141\n",
      "Epoch 20/100\n",
      " - 430s - loss: 0.5883 - acc: 0.7192 - mean_squared_error: 0.1949 - val_loss: 0.5884 - val_acc: 0.7199 - val_mean_squared_error: 0.1940\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.72141\n",
      "Epoch 21/100\n",
      " - 433s - loss: 0.5914 - acc: 0.7185 - mean_squared_error: 0.1950 - val_loss: 0.5924 - val_acc: 0.7193 - val_mean_squared_error: 0.1950\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.72141\n",
      "Epoch 22/100\n",
      " - 429s - loss: 0.6067 - acc: 0.7183 - mean_squared_error: 0.1951 - val_loss: 0.6172 - val_acc: 0.7180 - val_mean_squared_error: 0.1955\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.72141\n",
      "Epoch 23/100\n",
      " - 427s - loss: 0.6359 - acc: 0.7179 - mean_squared_error: 0.1956 - val_loss: 0.6498 - val_acc: 0.7178 - val_mean_squared_error: 0.1957\n",
      "\n",
      "Epoch 00023: val_acc did not improve from 0.72141\n",
      "Epoch 24/100\n",
      " - 427s - loss: 0.6673 - acc: 0.7190 - mean_squared_error: 0.1962 - val_loss: 0.7166 - val_acc: 0.7200 - val_mean_squared_error: 0.1966\n",
      "\n",
      "Epoch 00024: val_acc did not improve from 0.72141\n",
      "Epoch 25/100\n",
      " - 427s - loss: 0.6377 - acc: 0.7192 - mean_squared_error: 0.1960 - val_loss: 0.6331 - val_acc: 0.7201 - val_mean_squared_error: 0.1951\n",
      "\n",
      "Epoch 00025: val_acc did not improve from 0.72141\n",
      "Epoch 26/100\n",
      " - 430s - loss: 0.7172 - acc: 0.7199 - mean_squared_error: 0.1970 - val_loss: 0.6704 - val_acc: 0.7205 - val_mean_squared_error: 0.1959\n",
      "\n",
      "Epoch 00026: val_acc did not improve from 0.72141\n",
      "Epoch 27/100\n",
      " - 424s - loss: 0.7451 - acc: 0.7202 - mean_squared_error: 0.1972 - val_loss: 0.7811 - val_acc: 0.7204 - val_mean_squared_error: 0.1973\n",
      "\n",
      "Epoch 00027: val_acc did not improve from 0.72141\n",
      "Epoch 28/100\n",
      " - 423s - loss: 0.7556 - acc: 0.7201 - mean_squared_error: 0.1976 - val_loss: 0.8518 - val_acc: 0.7204 - val_mean_squared_error: 0.1989\n",
      "\n",
      "Epoch 00028: val_acc did not improve from 0.72141\n",
      "Epoch 29/100\n",
      " - 424s - loss: 0.9893 - acc: 0.7200 - mean_squared_error: 0.2019 - val_loss: 1.0731 - val_acc: 0.7205 - val_mean_squared_error: 0.2030\n",
      "\n",
      "Epoch 00029: val_acc did not improve from 0.72141\n",
      "Epoch 30/100\n",
      " - 423s - loss: 1.1293 - acc: 0.7203 - mean_squared_error: 0.2045 - val_loss: 1.1750 - val_acc: 0.7206 - val_mean_squared_error: 0.2050\n",
      "\n",
      "Epoch 00030: val_acc did not improve from 0.72141\n",
      "Epoch 31/100\n",
      " - 424s - loss: 1.1865 - acc: 0.7205 - mean_squared_error: 0.2056 - val_loss: 1.1679 - val_acc: 0.7208 - val_mean_squared_error: 0.2050\n",
      "\n",
      "Epoch 00031: val_acc did not improve from 0.72141\n",
      "Epoch 32/100\n",
      " - 423s - loss: 0.8050 - acc: 0.7199 - mean_squared_error: 0.1993 - val_loss: 0.6942 - val_acc: 0.7209 - val_mean_squared_error: 0.1961\n",
      "\n",
      "Epoch 00032: val_acc did not improve from 0.72141\n",
      "Epoch 33/100\n",
      " - 422s - loss: 0.7357 - acc: 0.7205 - mean_squared_error: 0.1974 - val_loss: 0.7913 - val_acc: 0.7199 - val_mean_squared_error: 0.1984\n",
      "\n",
      "Epoch 00033: val_acc did not improve from 0.72141\n",
      "Epoch 34/100\n",
      " - 422s - loss: 0.8734 - acc: 0.7203 - mean_squared_error: 0.2001 - val_loss: 0.9757 - val_acc: 0.7204 - val_mean_squared_error: 0.2015\n",
      "\n",
      "Epoch 00034: val_acc did not improve from 0.72141\n",
      "Epoch 35/100\n",
      " - 423s - loss: 1.1066 - acc: 0.7201 - mean_squared_error: 0.2045 - val_loss: 1.2118 - val_acc: 0.7200 - val_mean_squared_error: 0.2065\n",
      "\n",
      "Epoch 00035: val_acc did not improve from 0.72141\n",
      "Epoch 36/100\n",
      " - 427s - loss: 1.3413 - acc: 0.7154 - mean_squared_error: 0.2124 - val_loss: 1.7226 - val_acc: 0.7136 - val_mean_squared_error: 0.2241\n",
      "\n",
      "Epoch 00036: val_acc did not improve from 0.72141\n",
      "Epoch 37/100\n",
      " - 433s - loss: 4.5387 - acc: 0.6951 - mean_squared_error: 0.3005 - val_loss: 4.5434 - val_acc: 0.7166 - val_mean_squared_error: 0.2829\n",
      "\n",
      "Epoch 00037: val_acc did not improve from 0.72141\n",
      "Epoch 38/100\n",
      " - 434s - loss: 4.5544 - acc: 0.7172 - mean_squared_error: 0.2828 - val_loss: 4.5418 - val_acc: 0.7180 - val_mean_squared_error: 0.2820\n",
      "\n",
      "Epoch 00038: val_acc did not improve from 0.72141\n",
      "Epoch 39/100\n",
      " - 433s - loss: 4.5422 - acc: 0.7180 - mean_squared_error: 0.2820 - val_loss: 4.5369 - val_acc: 0.7182 - val_mean_squared_error: 0.2817\n",
      "\n",
      "Epoch 00039: val_acc did not improve from 0.72141\n",
      "Epoch 40/100\n",
      " - 437s - loss: 4.5405 - acc: 0.7180 - mean_squared_error: 0.2820 - val_loss: 4.5354 - val_acc: 0.7184 - val_mean_squared_error: 0.2816\n",
      "\n",
      "Epoch 00040: val_acc did not improve from 0.72141\n",
      "Epoch 41/100\n",
      " - 438s - loss: 4.5367 - acc: 0.7183 - mean_squared_error: 0.2817 - val_loss: 4.5348 - val_acc: 0.7184 - val_mean_squared_error: 0.2816\n",
      "\n",
      "Epoch 00041: val_acc did not improve from 0.72141\n",
      "Epoch 42/100\n",
      " - 437s - loss: 4.5354 - acc: 0.7184 - mean_squared_error: 0.2816 - val_loss: 4.5437 - val_acc: 0.7177 - val_mean_squared_error: 0.2823\n",
      "\n",
      "Epoch 00042: val_acc did not improve from 0.72141\n",
      "Epoch 43/100\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-91-6b543c8a5070>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m               metrics=['accuracy','mse'])\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_standardised\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_standardised\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mchk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    193\u001b[0m                 \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'batch'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m                 \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 195\u001b[0;31m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices_for_conversion_to_dense\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=11,kernel_initializer='uniform',activation='relu'))\n",
    "model.add(Dense(8,kernel_initializer='uniform',activation='relu'))\n",
    "model.add(Dense(1,kernel_initializer='uniform',activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy','mse'])\n",
    "\n",
    "chk = ModelCheckpoint('train_model_all_data.h5', monitor='val_acc', save_best_only=True, mode='max', verbose=1)\n",
    "\n",
    "history = model.fit(X_train_standardised, y_train.values, validation_data=(X_test_standardised, y_test), epochs=100, batch_size=32, callbacks=[chk], verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "e1dGDodWFI0V"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Barnett\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\Barnett\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    }
   ],
   "source": [
    "saved_model = load_model('train_model_all_data.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "MOHCUGQIOxrv",
    "outputId": "01eacc39-c72b-4bf5-bf1f-8baace4e21f8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['loss', 'acc', 'mean_squared_error']"
      ]
     },
     "execution_count": 100,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.metrics_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "id": "5Se9f_Zu9y2H",
    "outputId": "e9f5526d-fc31-4472-d721-a83412c6551f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3195797/3195797 [==============================] - 79s 25us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5833876934721798, 0.721412530270376, 0.19410793877640456]"
      ]
     },
     "execution_count": 106,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saved_model.evaluate(X_test_standardised, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xzgY1wnjbepZ"
   },
   "outputs": [],
   "source": [
    "y_pred = saved_model.predict_classes(X_test_standardised)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5488349737992039"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "id": "_l-6z4bzc9k5",
    "outputId": "f5f368f1-a95e-4bc9-de93-8c3989cdfb2b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2189624   53823]\n",
      " [ 836486  115864]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 178
    },
    "colab_type": "code",
    "id": "jf9tqTUodjUS",
    "outputId": "6e95acfb-c9ec-4ddf-acda-96ef1d259f6b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.98      0.83   2243447\n",
      "           1       0.68      0.12      0.21    952350\n",
      "\n",
      "    accuracy                           0.72   3195797\n",
      "   macro avg       0.70      0.55      0.52   3195797\n",
      "weighted avg       0.71      0.72      0.64   3195797\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
